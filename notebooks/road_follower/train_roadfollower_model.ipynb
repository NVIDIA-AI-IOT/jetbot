{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Follower - Train Model\n",
    "\n",
    "This is Host side Jupyter Notebook for project located under the name \"road_follower\" on your JetBot. We will use this notebook to train road following model. In this project we will be using Regression (continuous value output) to train JetBot where to move steering! \n",
    "\n",
    "We will be using PyTorch deep learning framework to train ResNet18 neural network architecture model for road follower application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "import PIL.Image\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and extract data\n",
    "\n",
    "Before you start, you should upload the ``dataset_roadfollower_{date_time}.zip`` file that you created in the ``data_collection.ipynb`` notebook on the robot. \n",
    "\n",
    "You can use scp to download data from your JetBot as follows:\n",
    "\n",
    "`` scp jetbot@<ip_address>:<dataset_directory_path> . ``\n",
    "\n",
    "You should then extract this dataset by calling the command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q lego_city_dataset_all_2019-03-16_12-52-20.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a folder named ``dataset_all`` appear in the file browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset Instance\n",
    "Now we use the abstract class representing a dataset available with the ``torch.utils.data.Dataset`` package.  We attach transforms from the ``torchvision.transforms`` package to prepare the data for training.\n",
    "\n",
    "Each file in dataset is labelled with ``steering_<>_<>_<>_<>_<>_<>.jpg`` \n",
    "Thus, we will use from 9 to 12 as steering label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steering(path):\n",
    "    return (float(int(path[3:6])) - 50.0) / 50.0\n",
    "\n",
    "def get_throttle(path):\n",
    "    return (float(int(path[6:9])) - 50.0) / 50.0\n",
    "class SteeringDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, directory, stdev=0.3, nbins=21):\n",
    "        self.nbins = nbins\n",
    "        self.stdev = stdev\n",
    "        self.directory = directory\n",
    "        self.image_paths = glob.glob(os.path.join(directory, '*.jpg'))\n",
    "        self.color_jitter = transforms.ColorJitter(0.1, 0.1, 0.1, 0.1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = PIL.Image.open(image_path)\n",
    "        \n",
    "        image = self.color_jitter(image)\n",
    "        image = transforms.functional.resize(image, (224, 224))\n",
    "        image = transforms.functional.to_tensor(image)\n",
    "        image = transforms.functional.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        \n",
    "        steering = float(get_steering(os.path.basename(image_path)))   \n",
    "        throttle = float(get_throttle(os.path.basename(image_path)))\n",
    "        return image, torch.tensor([steering]).float(), torch.tensor([throttle]).float()\n",
    "\n",
    "dataset = SteeringDataset('dataset_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train and test sets\n",
    "Once we read dataset, we will split data set in train and test sets. In this example we split train and test a 90%-10%. The test set will be used to verify the accuracy of the model we train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percent = 0.1\n",
    "BATCH_SIZE = 64\n",
    "num_test = int(test_percent * len(dataset))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - num_test, num_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data loaders to load data in batches\n",
    "\n",
    "We use ``DataLoader`` class to load data in batches, shuffle data and allow using multi-subprocesses. In this example we use batch size of 64. Batch size will be based on memory available with your GPU and it can impact accuracy of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Network Model \n",
    "\n",
    "We use ResNet-18 model available on PyTorch TorchVision. \n",
    "\n",
    "In a process called transfer learning, we can repurpose a pre-trained model (trained on millions of images) for a new task that has possibly much less data available.\n",
    "\n",
    "\n",
    "More details on ResNet-18 : https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
    "\n",
    "More Details on Transfer Learning: https://www.youtube.com/watch?v=yofjFQddwHE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet model has fully connect (fc) final layer with 512 as ``in_features`` and we will be training for regression thus ``out_features`` as 1\n",
    "\n",
    "Finally, we transfer our model for execution on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = torch.nn.Linear(512, 1)\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Regression:\n",
    "\n",
    "We train for 50 epochs and save best model if the loss is reduced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Test Loss: 168.965347\n",
      "Epoch : 1, Test Loss: 14.124955\n",
      "Epoch : 2, Test Loss: 36.150612\n",
      "Epoch : 3, Test Loss: 41.710323\n",
      "Epoch : 4, Test Loss: 17.329863\n",
      "Epoch : 5, Test Loss: 7.215171\n",
      "Epoch : 6, Test Loss: 3.752449\n",
      "Epoch : 7, Test Loss: 2.276010\n",
      "Epoch : 8, Test Loss: 0.891368\n",
      "Epoch : 9, Test Loss: 0.274711\n",
      "Epoch : 10, Test Loss: 0.157284\n",
      "Epoch : 11, Test Loss: 0.083652\n",
      "Epoch : 12, Test Loss: 0.029237\n",
      "Epoch : 13, Test Loss: 0.024496\n",
      "Epoch : 14, Test Loss: 0.018810\n",
      "Epoch : 15, Test Loss: 0.017174\n",
      "Epoch : 16, Test Loss: 0.018829\n",
      "Epoch : 17, Test Loss: 0.016731\n",
      "Epoch : 18, Test Loss: 0.013730\n",
      "Epoch : 19, Test Loss: 0.014714\n",
      "Epoch : 20, Test Loss: 0.015781\n",
      "Epoch : 21, Test Loss: 0.015388\n",
      "Epoch : 22, Test Loss: 0.015901\n",
      "Epoch : 23, Test Loss: 0.016596\n",
      "Epoch : 24, Test Loss: 0.015942\n",
      "Epoch : 25, Test Loss: 0.013331\n",
      "Epoch : 26, Test Loss: 0.013768\n",
      "Epoch : 27, Test Loss: 0.015897\n",
      "Epoch : 28, Test Loss: 0.014649\n",
      "Epoch : 29, Test Loss: 0.014428\n",
      "Epoch : 30, Test Loss: 0.012016\n",
      "Epoch : 31, Test Loss: 0.016218\n",
      "Epoch : 32, Test Loss: 0.014335\n",
      "Epoch : 33, Test Loss: 0.016122\n",
      "Epoch : 34, Test Loss: 0.016852\n",
      "Epoch : 35, Test Loss: 0.012890\n",
      "Epoch : 36, Test Loss: 0.013422\n",
      "Epoch : 37, Test Loss: 0.011382\n",
      "Epoch : 38, Test Loss: 0.014649\n",
      "Epoch : 39, Test Loss: 0.021070\n",
      "Epoch : 40, Test Loss: 0.013088\n",
      "Epoch : 41, Test Loss: 0.012061\n",
      "Epoch : 42, Test Loss: 0.020098\n",
      "Epoch : 43, Test Loss: 0.012507\n",
      "Epoch : 44, Test Loss: 0.011905\n",
      "Epoch : 45, Test Loss: 0.015623\n",
      "Epoch : 46, Test Loss: 0.018272\n",
      "Epoch : 47, Test Loss: 0.013508\n",
      "Epoch : 48, Test Loss: 0.016488\n",
      "Epoch : 49, Test Loss: 0.013075\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 50\n",
    "BEST_MODEL_PATH = 'best_steering_model_forward.pth'\n",
    "best_loss = 1e9\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in iter(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = F.mse_loss(outputs, labels)\n",
    "        train_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    for images, labels in iter(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = F.mse_loss(outputs, labels)\n",
    "        test_loss += loss\n",
    "    test_loss /= len(test_loader)\n",
    "    \n",
    "    print('Epoch : %d, Test Loss: %f' % (epoch, test_loss))\n",
    "    if test_loss < best_loss:\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        best_loss = test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained, it will generate ``best_steering_model_forward.pth`` file which you can use for inferencing.\n",
    "\n",
    "You can use scp to upload your model file (.pth) to JetBot as follows:\n",
    "\n",
    "`` scp best_steering_model_forward.pth jetbot@<ip_address>:<inference_path>  ``\n",
    "\n",
    "or\n",
    "\n",
    " Select ``Right click`` -> ``Download`` to download the model to your workstation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
